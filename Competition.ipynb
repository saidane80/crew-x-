{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saidane80/crew-x-/blob/master/Competition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download data from GCP bucket\n",
        "import sys\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "  !gsutil -m cp -r gs://indaba-data .\n",
        "else:\n",
        "  !mkdir -p indaba-data/train\n",
        "  !wget -P indaba-data/train https://storage.googleapis.com/indaba-data/train/train.csv --continue\n",
        "  !wget -P indaba-data/train https://storage.googleapis.com/indaba-data/train/train_mut.pt --continue\n",
        "  !wget -P indaba-data/train https://storage.googleapis.com/indaba-data/train/train_wt.pt --continue\n",
        "\n",
        "  !mkdir -p indaba-data/test\n",
        "  !wget -P indaba-data/test https://storage.googleapis.com/indaba-data/test/test.csv --continue\n",
        "  !wget -P indaba-data/test https://storage.googleapis.com/indaba-data/test/test_mut.pt --continue\n",
        "  !wget -P indaba-data/test https://storage.googleapis.com/indaba-data/test/test_wt.pt --continue"
      ],
      "metadata": {
        "id": "DEk5q0rhjBWZ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports and moving to working directory\n",
        "import torch \n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# move to data folder\n",
        "%cd indaba-data"
      ],
      "metadata": {
        "id": "Jvd8ERpgTvji",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Embedding tensors & Traing csv\n",
        "# Embeddings were calculated using the ESM 650M pretrained model \n",
        "# Tensor shape of embedded data:  [data_len,1280] \n",
        "# There are no sequences in the Embedding tensors as we've performed an average of it (torch.mean(embed, dim=1))\n",
        "# More details in https://huggingface.co/facebook/esm2_t33_650M_UR50D\n",
        "\n",
        "wt_emb = torch.load(\"train/train_wt.pt\")\n",
        "mut_emb = torch.load(\"train/train_mut.pt\")\n",
        "df = pd.read_csv(\"train/train.csv\")"
      ],
      "metadata": {
        "id": "36ZgVoj5odV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [Recommended] Split data into train and validation \n",
        "#TODO"
      ],
      "metadata": {
        "id": "zr0Njii0pRvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the dataset class\n",
        "class EmbeddingDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self,mut_pt, wt_pt, data_df):\n",
        "    self.pt_mut = mut_pt\n",
        "    self.pt_wt = wt_pt\n",
        "    self.df = data_df\n",
        "  \n",
        "  def __len__(self):\n",
        "      return self.pt_mut.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    o1=self.pt_mut[index,:]\n",
        "    o2=self.pt_wt[index,:]\n",
        "    if \"ddg\" in self.df:\n",
        "      df_out=torch.Tensor([self.df[\"ddg\"][index]])\n",
        "    else:\n",
        "      df_out=torch.Tensor([self.df[\"ID\"][index]])\n",
        "    return  self.pt_mut[index,:],self.pt_wt[index,:],df_out "
      ],
      "metadata": {
        "id": "BEEH-ZWJgdUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating training dataset and dataloader\n",
        "train_dataset = EmbeddingDataset(wt_emb, mut_emb, df)\n",
        "# preparing a dataloader for the training\n",
        "train_dataloader = torch.utils.data.dataloader.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=32,\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "    )\n",
        "# [Recommended] Use Data validation loader too\n"
      ],
      "metadata": {
        "id": "RrRVCI8siRfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a simple pytorch model\n",
        "# A dummy model (2-param) that demonstrates the usage of the dataset\n",
        "\n",
        "class StabilityModel(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(StabilityModel, self).__init__()\n",
        "    self.lin = torch.nn.Linear(1,1)\n",
        "\n",
        "  def forward(self, x, y):\n",
        "    # run the forward pass\n",
        "    # output should be the stability estimation [batch,estim]\n",
        "    return self.lin(torch.mean(x-y,dim=1).reshape(-1,1)) "
      ],
      "metadata": {
        "id": "9NuUlQRK8gHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0eRkdLwDGVwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of training script\n",
        "device = torch.device(\"cuda\")\n",
        "model =  StabilityModel().to(device)\n",
        "optimizer = torch.optim.Adadelta(model.parameters(), lr=0.0001)\n",
        "criterion = torch.nn.MSELoss()\n",
        "epoch_loss = 0\n",
        "for i in range(1):\n",
        "  epoch_loss = 0\n",
        "  for batch_idx, (data_mut,data_wt , target) in tqdm(enumerate(train_dataloader)):\n",
        "      # extract input from datallader\n",
        "      x1 = data_wt.to(device)\n",
        "      x2 = data_mut.to(device)\n",
        "      y = target.to(device)\n",
        "      # make prediction\n",
        "      y_pred = model(x1,x2)\n",
        "      # calculate loss and run optimizer\n",
        "      loss = torch.sqrt(criterion(y, y_pred))\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      epoch_loss += loss\n",
        "  print(\"epoch_\",i,\" = \", epoch_loss/len(train_dataloader))\n",
        "  # [Recommended] Save trained models to select best checkpoint for prediction (or add prediction in the epochs loop)"
      ],
      "metadata": {
        "id": "ndGfhMrjlmUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction & submission"
      ],
      "metadata": {
        "id": "9GDKutS_nKOT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load embedding tensors & traing csv\n",
        "wt_test_emb = torch.load(\"test/test_wt.pt\")\n",
        "mut_test_emb = torch.load(\"test/test_mut.pt\")\n",
        "df_test = pd.read_csv(\"test/test.csv\")"
      ],
      "metadata": {
        "id": "ave_DDMp8fo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating testing dataset and loading the embedding\n",
        "test_dataset = EmbeddingDataset(wt_test_emb,mut_test_emb,df_test)\n",
        "# preparing a dataloader for the testing\n",
        "test_dataloader = torch.utils.data.dataloader.DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=32,\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "    )"
      ],
      "metadata": {
        "id": "9Xmav2yhm_Di"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_result = pd.DataFrame()\n",
        "with torch.no_grad():\n",
        "  for batch_idx, (data_mut,data_wt , target) in tqdm(enumerate(test_dataloader)):\n",
        "    x1 = data_wt.to(device)\n",
        "    x2 = data_mut.to(device)\n",
        "    id = target.to(device)\n",
        "    # make prediction\n",
        "    y_pred = model(x1,x2)\n",
        "    df_result = pd.concat([df_result, pd.DataFrame({\"ID\":id.squeeze().cpu().numpy().astype(int) , \"ddg\" : y_pred.squeeze().cpu().numpy()})])"
      ],
      "metadata": {
        "id": "DiylsXvjqOul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_result.to_csv(\"submission.csv\",index=False)"
      ],
      "metadata": {
        "id": "FPm-a2USexgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AhEk8JGCIlIO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}